{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PIZD1vnM08zL"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning and optimization\n",
    "import optuna\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback, TuneReportCheckpointCallback\n",
    "\n",
    "# PyTorch Lightning and callbacks\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, Callback, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# Metrics\n",
    "from torchmetrics import MeanAbsoluteError, MeanAbsolutePercentageError, MetricCollection\n",
    "\n",
    "# Darts (Time series forecasting)\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.models import DLinearModel, LightGBMModel, BlockRNNModel, TiDEModel\n",
    "\n",
    "# Data handling and preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorboard\n",
    "\n",
    "# System utilities\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRL7Bd-51F6b"
   },
   "source": [
    "Load Data / Spilt Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JB4QAplQd-T",
    "outputId": "844a32da-ecac-4a6c-815f-ca6d65d0ac3d"
   },
   "outputs": [],
   "source": [
    "# 步骤1: 加载CSV文件\n",
    "df = pd.read_csv('../DataSet/EDvisitfileL.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# 确保'date'列是DateTime类型\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# 分割数据集为训练集、验证集和测试集（假设您已经根据时间排序）\n",
    "train_end = 3362            #L: 3362, T:3372, Ka:3208, Ke:3274, Y:2557, C: 3237\n",
    "val_end = 3727              #L: 3727, T:3737, Ka:3573, Ke:3639, Y:2622, C: 3602\n",
    "\n",
    "# Split the DataFrame\n",
    "train_df = df.iloc[:train_end]\n",
    "val_df = df.iloc[train_end:val_end]\n",
    "test_df = df.iloc[val_end:]\n",
    "\n",
    "# 步骤2: 使用MinMaxScaler缩放数据\n",
    "# 定义并拟合scaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_df[['No']])  # 只用训练数据拟合scaler\n",
    "\n",
    "# 缩放训练集和验证集\n",
    "train_df.loc[:, 'No_scaled'] = scaler.transform(train_df[['No']])\n",
    "val_df.loc[:, 'No_scaled'] = scaler.transform(val_df[['No']])\n",
    "test_df.loc[:, 'No_scaled'] = scaler.transform(test_df[['No']])  # 用相同的scaler转换测试集以避免数据泄露\n",
    "\n",
    "# 转换为TimeSeries对象\n",
    "train_series = TimeSeries.from_dataframe(train_df, value_cols='No_scaled')\n",
    "val_series = TimeSeries.from_dataframe(val_df, value_cols='No_scaled')\n",
    "test_series = TimeSeries.from_dataframe(test_df, value_cols='No_scaled')\n",
    "\n",
    "# 原始数据转换为TimeSeries对象，如果需要\n",
    "train_series_origin = TimeSeries.from_dataframe(train_df, value_cols='No')\n",
    "val_series_origin = TimeSeries.from_dataframe(val_df, value_cols='No')\n",
    "test_series_origin = TimeSeries.from_dataframe(test_df, value_cols='No')\n",
    "\n",
    "# 选择需要的列创建多变量时间序列(都是one hot coding)\n",
    "columns = ['Dayoff', 'Mon', 'Tue', 'Wed', 'Thr', 'Fri', 'Sat', 'Sun',  'YearScaled',\n",
    "           'MonthScaled', 'Dayscaled', 'NewYear', '3Lock', 'Outbreak','COVID19']\n",
    "df_multivariate = df[columns]\n",
    "\n",
    "# 将DataFrame转换为多变量时间序列\n",
    "ED_covariates = TimeSeries.from_dataframe(df_multivariate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QDhOOMG1KF7"
   },
   "source": [
    "Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossLoggingCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.val_losses = []  # To store validation losses\n",
    "        self.train_losses = []  # To store training losses\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        val_loss = trainer.callback_metrics[\"val_loss\"].item()\n",
    "        self.val_losses.append(val_loss)\n",
    "        print(f\"Epoch {trainer.current_epoch}: val_loss={val_loss}\")\n",
    "        # Updated report call\n",
    "        train.report({\"loss\": val_loss})  # Report the validation loss to Ray Train\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module, unused=None):\n",
    "        if \"train_loss\" in trainer.callback_metrics:\n",
    "            train_loss = trainer.callback_metrics[\"train_loss\"].item()\n",
    "            self.train_losses.append(train_loss)\n",
    "            print(f\"Epoch {trainer.current_epoch}: train_loss={train_loss}\")\n",
    "loss_logging_callback = LossLoggingCallback()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "W9kikpPwzVdk"
   },
   "outputs": [],
   "source": [
    "# Create the model using model_args from Ray Tune\n",
    "def train_model(model_args, callbacks, train, val):\n",
    "    torch_metrics = MetricCollection([MeanAbsolutePercentageError(), MeanAbsoluteError()])\n",
    "    \n",
    "    # Customize the ModelCheckpoint callback\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=\"checkpoints\",\n",
    "        filename=\"{epoch}-{val_loss:.2f}\",\n",
    "        every_n_epochs=5,\n",
    "    )\n",
    "    \n",
    "    model = LightGBMModel(\n",
    "        output_chunk_length=30,\n",
    "        lags=7,\n",
    "        lags_past_covariates=model_args['lags_past_covariates'],\n",
    "        verbose=-1,    \n",
    "        )\n",
    "\n",
    "    model.fit(\n",
    "    series=[train_series],\n",
    "    past_covariates=[ED_covariates],\n",
    "    val_series=[val_series],\n",
    "    val_past_covariates=[ED_covariates]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "e2pX_rH51IHe"
   },
   "outputs": [],
   "source": [
    "# set up ray tune callback\n",
    "config = {\n",
    "    'lags_past_covariates': tune.randint(1,30),\n",
    "}\n",
    "\n",
    "# earlystopping\n",
    "my_stopper = EarlyStopping(\n",
    "    monitor=\"loss\",\n",
    "    patience=5,\n",
    "    min_delta=0.001,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "\n",
    "tune_callback = TuneReportCheckpointCallback(\n",
    "    {\n",
    "        \"loss\": \"val_loss\",\n",
    "    },\n",
    "    on=\"validation_end\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "reporter = CLIReporter(\n",
    "    parameter_columns=list(config.keys()),\n",
    "    metric_columns=[\"loss\", \"MAPE\", \"training_iteration\"],\n",
    ")\n",
    "\n",
    "optuna_search = OptunaSearch(metric=\"loss\",mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h4L522X41XIL",
    "outputId": "4df26e54-fe79-499c-938d-b376c0e22c76"
   },
   "outputs": [],
   "source": [
    "# Run Ray Tune, optimize hyperparameters by minimizing the MAPE on the validation set\n",
    "num_samples = 30\n",
    "\n",
    "scheduler = ASHAScheduler(max_t=1000, grace_period=5, reduction_factor=2)\n",
    "\n",
    "train_fn_with_parameters = tune.with_parameters(\n",
    "    train_model, callbacks=[my_stopper, tune_callback], train=train_series, val=val_series,\n",
    ")\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_fn_with_parameters,\n",
    "    #resources_per_trial=resources_per_trial,\n",
    "    metric=\"loss\",  # any value in TuneReportCallback.\n",
    "    mode=\"min\",\n",
    "    config=config,\n",
    "    num_samples=num_samples,\n",
    "    search_alg=optuna_search,\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter,\n",
    "    trial_dirname_creator=lambda trial: str(trial),\n",
    "    name=\"tune_darts\",\n",
    ")\n",
    "\n",
    "print(\"Best hyperparameters found were: \", analysis.best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
