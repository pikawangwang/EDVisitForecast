{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PIZD1vnM08zL"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning and optimization\n",
    "import optuna\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback, TuneReportCheckpointCallback\n",
    "\n",
    "# PyTorch Lightning and callbacks\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, Callback, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# Metrics\n",
    "from torchmetrics import MeanAbsoluteError, MeanAbsolutePercentageError, MetricCollection\n",
    "\n",
    "# Darts (Time series forecasting)\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.models import DLinearModel, LightGBMModel, BlockRNNModel, TiDEModel\n",
    "\n",
    "# Data handling and preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorboard\n",
    "\n",
    "# System utilities\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRL7Bd-51F6b"
   },
   "source": [
    "Load Data / Spilt Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JB4QAplQd-T",
    "outputId": "844a32da-ecac-4a6c-815f-ca6d65d0ac3d"
   },
   "outputs": [],
   "source": [
    "# 步骤1: 加载CSV文件\n",
    "df = pd.read_csv('../DataSet/EDvisitfileC.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# 确保'date'列是DateTime类型\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# 分割数据集为训练集、验证集和测试集（假设您已经根据时间排序）\n",
    "train_end = 3237            #L: 3362, T:3372, Ka:3208, Ke:3274, Y:2557, C: 3237\n",
    "val_end = 3602              #L: 3727, T:3737, Ka:3573, Ke:3639, Y:2822, C: 3602\n",
    "\n",
    "# Split the DataFrame\n",
    "train_df = df.iloc[:train_end]\n",
    "val_df = df.iloc[train_end:val_end]\n",
    "test_df = df.iloc[val_end:]\n",
    "\n",
    "# 步骤2: 使用MinMaxScaler缩放数据\n",
    "# 定义并拟合scaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_df[['No']])  # 只用训练数据拟合scaler\n",
    "\n",
    "# 缩放训练集和验证集\n",
    "train_df.loc[:, 'No_scaled'] = scaler.transform(train_df[['No']])\n",
    "val_df.loc[:, 'No_scaled'] = scaler.transform(val_df[['No']])\n",
    "test_df.loc[:, 'No_scaled'] = scaler.transform(test_df[['No']])  # 用相同的scaler转换测试集以避免数据泄露\n",
    "\n",
    "# 转换为TimeSeries对象\n",
    "train_series = TimeSeries.from_dataframe(train_df, value_cols='No_scaled')\n",
    "val_series = TimeSeries.from_dataframe(val_df, value_cols='No_scaled')\n",
    "test_series = TimeSeries.from_dataframe(test_df, value_cols='No_scaled')\n",
    "\n",
    "# 原始数据转换为TimeSeries对象，如果需要\n",
    "train_series_origin = TimeSeries.from_dataframe(train_df, value_cols='No')\n",
    "val_series_origin = TimeSeries.from_dataframe(val_df, value_cols='No')\n",
    "test_series_origin = TimeSeries.from_dataframe(test_df, value_cols='No')\n",
    "\n",
    "# 选择需要的列创建多变量时间序列(都是one hot coding)\n",
    "columns = ['Dayoff', 'Mon', 'Tue', 'Wed', 'Thr', 'Fri', 'Sat', 'Sun',  'YearScaled',\n",
    "           'MonthScaled', 'Dayscaled', 'NewYear', '3Lock', 'Outbreak','COVID19']\n",
    "df_multivariate = df[columns]\n",
    "\n",
    "# 将DataFrame转换为多变量时间序列\n",
    "ED_covariates = TimeSeries.from_dataframe(df_multivariate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QDhOOMG1KF7"
   },
   "source": [
    "Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossLoggingCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.val_losses = []  # To store validation losses\n",
    "        self.train_losses = []  # To store training losses\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        val_loss = trainer.callback_metrics[\"val_loss\"].item()\n",
    "        self.val_losses.append(val_loss)\n",
    "        print(f\"Epoch {trainer.current_epoch}: val_loss={val_loss}\")\n",
    "        # Updated report call\n",
    "        train.report({\"loss\": val_loss})  # Report the validation loss to Ray Train\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module, unused=None):\n",
    "        if \"train_loss\" in trainer.callback_metrics:\n",
    "            train_loss = trainer.callback_metrics[\"train_loss\"].item()\n",
    "            self.train_losses.append(train_loss)\n",
    "            print(f\"Epoch {trainer.current_epoch}: train_loss={train_loss}\")\n",
    "loss_logging_callback = LossLoggingCallback()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9kikpPwzVdk"
   },
   "outputs": [],
   "source": [
    "# Create the model using model_args from Ray Tune\n",
    "def train_model(model_args, callbacks, train, val):\n",
    "    torch_metrics = MetricCollection([MeanAbsolutePercentageError(), MeanAbsoluteError()])\n",
    "    \n",
    "    # Customize the ModelCheckpoint callback\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=\"checkpoints\",\n",
    "        filename=\"{epoch}-{val_loss:.2f}\",\n",
    "        every_n_epochs=5,\n",
    "    )\n",
    "    \n",
    "    model = TiDEModel(\n",
    "        input_chunk_length=30,\n",
    "        output_chunk_length=1,\n",
    "        pl_trainer_kwargs={\"callbacks\": callbacks, \"enable_progress_bar\": False},\n",
    "        log_tensorboard=True,\n",
    "        **model_args)\n",
    "\n",
    "    model.fit(\n",
    "    series=[train_series],\n",
    "    past_covariates=[ED_covariates],\n",
    "    val_series=[val_series],\n",
    "    val_past_covariates=[ED_covariates]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2pX_rH51IHe"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'hidden_size': tune.randint(20, 720),\n",
    "    'lr_scheduler_kwargs': tune.uniform(0, 0.01),\n",
    "    #'temporal_decoder_hidden': tune.choice([8, 16, 32]),\n",
    "    \"num_encoder_layers\": tune.randint(1, 6),\n",
    "    \"num_decoder_layers\": tune.randint(1, 6),\n",
    "    \"dropout\": tune.uniform(0, 0.8),\n",
    "}\n",
    "\n",
    "# earlystopping\n",
    "my_stopper = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    min_delta=0.001,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "\n",
    "tune_callback = TuneReportCheckpointCallback(\n",
    "    {\n",
    "        \"loss\": \"val_loss\",\n",
    "    },\n",
    "    on=\"validation_end\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "reporter = CLIReporter(\n",
    "    parameter_columns=list(config.keys()),\n",
    "    metric_columns=[\"loss\", \"MAPE\", \"training_iteration\"],\n",
    ")\n",
    "\n",
    "optuna_search = OptunaSearch(metric=\"loss\", mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h4L522X41XIL",
    "outputId": "4df26e54-fe79-499c-938d-b376c0e22c76"
   },
   "outputs": [],
   "source": [
    "# Run Ray Tune, optimize hyperparameters by minimizing the MAPE on the validation set\n",
    "num_samples = 30\n",
    "\n",
    "scheduler = ASHAScheduler(max_t=1000, grace_period=5, reduction_factor=2)\n",
    "\n",
    "train_fn_with_parameters = tune.with_parameters(\n",
    "    train_model, callbacks=[my_stopper, tune_callback], train=train_series, val=val_series,\n",
    ")\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_fn_with_parameters,\n",
    "    #resources_per_trial=resources_per_trial,\n",
    "    metric=\"loss\",  # any value in TuneReportCallback.\n",
    "    mode=\"min\",\n",
    "    config=config,\n",
    "    num_samples=num_samples,\n",
    "    search_alg=optuna_search,\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter,\n",
    "    trial_dirname_creator=lambda trial: str(trial),\n",
    "    name=\"tune_darts\",\n",
    ")\n",
    "\n",
    "print(\"Best hyperparameters found were: \", analysis.best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analysis.results_df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "pd.DataFrame.iteritems = pd.DataFrame.items\n",
    "\n",
    "df = analysis.results_df\n",
    "\n",
    "# 假設 df 是你的 DataFrame\n",
    "fig = px.parallel_coordinates(df, \n",
    "                              dimensions=['config/hidden_size', 'config/lr_scheduler_kwargs',\n",
    "                                          'config/num_encoder_layers','config/num_decoder_layers','config/dropout', 'loss'],\n",
    "                              color='loss',\n",
    "                              labels={\"config/hidden_size\": \"Hidden Size\",\n",
    "                                      'config/num_encoder_layers': \"Encoder_layers\",\n",
    "                                      'config/num_decoder_layers': \"Decoder_layers\",\n",
    "                                      'config/dropout': \"Dropout\",\n",
    "                                      \"config/lr_scheduler_kwargs\": \"Learning Rate\",\n",
    "                                      \"loss\": \"MSE\",\n",
    "                                    \n",
    "                                     },\n",
    "                              color_continuous_scale=px.colors.diverging.Tealrose,  # 色彩範圍\n",
    "                              #color_continuous_midpoint=0.0025\n",
    "                             )  # 中間點，根據數據適當調整\n",
    "\n",
    "# 設定每個維度的範圍\n",
    "fig.update_traces(dimensions=[\n",
    "    dict(range=[min(df['config/hidden_size']), max(df['config/hidden_size'])], label='Hidden layer', values=df['config/hidden_size']),\n",
    "    dict(range=[min(df['config/lr_scheduler_kwargs']), max(df['config/lr_scheduler_kwargs'])], label='Learning Rate', values=df['config/lr_scheduler_kwargs']),\n",
    "    dict(range=[min(df['config/dropout']), max(df['config/dropout'])], label='Dropout', values=df['config/dropout']),\n",
    "    dict(range=[min(df['config/num_encoder_layers']), max(df['config/num_encoder_layers'])], label='Encoder_layers', values=df['config/num_encoder_layers']),\n",
    "    dict(range=[min(df['config/num_decoder_layers']), max(df['config/num_decoder_layers'])], label='Decoder_layers', values=df['config/num_decoder_layers']),\n",
    "    dict(range=[min(df['loss']), max(df['loss'])], label='MSE', values=df['loss']),\n",
    "])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('C:\\\\Users\\\\ian11\\\\EDtimeseriesForecast\\\\EDtimeseriesForecast\\\\Result\\\\TiDE\\\\Chiayi\\\\Hypertuning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
